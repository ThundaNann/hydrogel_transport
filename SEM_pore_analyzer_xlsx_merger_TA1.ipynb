{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0d6444-9dd5-4e4f-9370-42f2de8ba296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select the folder containing your pore analysis Excel files...\n",
      "(The file dialog should appear on top of other windows)\n",
      "\n",
      "Searching for Excel files in: C:/Users/Talaial Alina/OneDrive - UCB-O365/Courses/Year 1/Fall Semester Aug-Dec 2020/CHEN 5840 - Independent Study/Hydrogels/SEM/04JUL25/4% gelatin/1X PBS\n",
      "\n",
      "Found 6 Excel files:\n",
      "  1. 0 cycles\\10\\0 cycles_pore_analysis_Custom_82.xlsx\n",
      "      → 1X PBS | 0 cycles | Replicate 10\n",
      "  2. 0 cycles\\11\\0 cycles_pore_analysis_Custom_91.xlsx\n",
      "      → 1X PBS | 0 cycles | Replicate 11\n",
      "  3. 0 cycles\\9\\0 cycles_pore_analysis_Custom_72.xlsx\n",
      "      → 1X PBS | 0 cycles | Replicate 9\n",
      "  4. 28 cycles\\10\\28 cycles_pore_analysis_Custom_82.xlsx\n",
      "      → 1X PBS | 28 cycles | Replicate 10\n",
      "  5. 28 cycles\\11\\28 cycles_pore_analysis_Multi-Otsu_lowest.xlsx\n",
      "      → 1X PBS | 28 cycles | Replicate 11\n",
      "  6. 28 cycles\\9\\28 cycles_pore_analysis_Multi-Otsu_lowest.xlsx\n",
      "      → 1X PBS | 28 cycles | Replicate 9\n",
      "\n",
      "Options:\n",
      "  1. Merge all files\n",
      "  2. Select specific files to merge\n",
      "  3. Cancel\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your choice (1-3):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 6 Excel files...\n",
      "\n",
      "Merging sheets to: C:/Users/Talaial Alina/OneDrive - UCB-O365/Courses/Year 1/Fall Semester Aug-Dec 2020/CHEN 5840 - Independent Study/Hydrogels/SEM/04JUL25/4% gelatin/1X PBS\\MERGED_pore_analysis_20250705_234918.xlsx\n",
      "\n",
      "  Processing file 1/6: 0 cycles_pore_analysis_Custom_82.xlsx\n",
      "    ✓ Copied 'Summary' → '1P-0C-R10-S'\n",
      "    ✓ Copied 'Pore Data' → '1P-0C-R10-P'\n",
      "    ✓ Copied 'Distribution Data' → '1P-0C-R10-D'\n",
      "    ✓ Copied 'Cumulative Data' → '1P-0C-R10-C'\n",
      "\n",
      "  Processing file 2/6: 0 cycles_pore_analysis_Custom_91.xlsx\n",
      "    ✓ Copied 'Summary' → '1P-0C-R11-S'\n",
      "    ✓ Copied 'Pore Data' → '1P-0C-R11-P'\n",
      "    ✓ Copied 'Distribution Data' → '1P-0C-R11-D'\n",
      "    ✓ Copied 'Cumulative Data' → '1P-0C-R11-C'\n",
      "\n",
      "  Processing file 3/6: 0 cycles_pore_analysis_Custom_72.xlsx\n",
      "    ✓ Copied 'Summary' → '1P-0C-R9-S'\n",
      "    ✓ Copied 'Pore Data' → '1P-0C-R9-P'\n",
      "    ✓ Copied 'Distribution Data' → '1P-0C-R9-D'\n",
      "    ✓ Copied 'Cumulative Data' → '1P-0C-R9-C'\n",
      "\n",
      "  Processing file 4/6: 28 cycles_pore_analysis_Custom_82.xlsx\n",
      "    ✓ Copied 'Summary' → '1P-28C-R10-S'\n",
      "    ✓ Copied 'Pore Data' → '1P-28C-R10-P'\n",
      "    ✓ Copied 'Distribution Data' → '1P-28C-R10-D'\n",
      "    ✓ Copied 'Cumulative Data' → '1P-28C-R10-C'\n",
      "\n",
      "  Processing file 5/6: 28 cycles_pore_analysis_Multi-Otsu_lowest.xlsx\n",
      "    ✓ Copied 'Summary' → '1P-28C-R11-S'\n",
      "    ✓ Copied 'Pore Data' → '1P-28C-R11-P'\n",
      "    ✓ Copied 'Distribution Data' → '1P-28C-R11-D'\n",
      "    ✓ Copied 'Cumulative Data' → '1P-28C-R11-C'\n",
      "\n",
      "  Processing file 6/6: 28 cycles_pore_analysis_Multi-Otsu_lowest.xlsx\n",
      "    ✓ Copied 'Summary' → '1P-28C-R9-S'\n",
      "    ✓ Copied 'Pore Data' → '1P-28C-R9-P'\n",
      "    ✓ Copied 'Distribution Data' → '1P-28C-R9-D'\n",
      "    ✓ Copied 'Cumulative Data' → '1P-28C-R9-C'\n",
      "\n",
      "  ✓ Created INDEX sheet with mapping information\n",
      "\n",
      "  Adjusting column widths...\n",
      "\n",
      "============================================================\n",
      "MERGE COMPLETE!\n",
      "============================================================\n",
      "Output file: MERGED_pore_analysis_20250705_234918.xlsx\n",
      "Location: C:/Users/Talaial Alina/OneDrive - UCB-O365/Courses/Year 1/Fall Semester Aug-Dec 2020/CHEN 5840 - Independent Study/Hydrogels/SEM/04JUL25/4% gelatin/1X PBS\n",
      "\n",
      "Total sheets copied: 24\n",
      "\n",
      "Sheet naming convention:\n",
      "  - Particle Type: First letter(s) (e.g., 'D' for DBPC HMSN)\n",
      "  - Cycles: Number + 'C' (e.g., '0C' for 0 cycles)\n",
      "  - Replicate: 'R' + number (e.g., 'R1' for replicate 1)\n",
      "  - Sheet Type: S=Summary, P=Pore Data, D=Distribution, C=Cumulative\n",
      "\n",
      "Example: 'D-0C-R1-S' = DBPC HMSN, 0 cycles, Replicate 1, Summary sheet\n",
      "\n",
      "The INDEX sheet contains the full mapping of abbreviated names to samples.\n",
      "\n",
      "Done! You can open the merged Excel file to view all results.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from datetime import datetime\n",
    "import platform\n",
    "import time\n",
    "\n",
    "def extract_sample_info(filepath):\n",
    "    \"\"\"Extract sample information from the file path\"\"\"\n",
    "    path_parts = Path(filepath).parts\n",
    "    \n",
    "    # Initialize variables\n",
    "    particle_type = None\n",
    "    cycles = None\n",
    "    replicate = None\n",
    "    gelatin_concentration = None\n",
    "    \n",
    "    # Extract information from path\n",
    "    for i, part in enumerate(path_parts):\n",
    "        # Extract gelatin concentration\n",
    "        if \"% gelatin\" in part:\n",
    "            gelatin_concentration = part\n",
    "        \n",
    "        # Extract particle type (e.g., \"DBPC HMSN\")\n",
    "        if i > 0 and \"% gelatin\" in path_parts[i-1]:\n",
    "            particle_type = part\n",
    "        \n",
    "        # Extract cycles\n",
    "        if \"cycles\" in part and not \"cycles_pore_analysis\" in part:\n",
    "            cycles = part\n",
    "        \n",
    "        # Extract replicate number (the folder before the filename)\n",
    "        if i == len(path_parts) - 2:  # Second to last element\n",
    "            replicate = part\n",
    "    \n",
    "    return {\n",
    "        'Gelatin_Concentration': gelatin_concentration,\n",
    "        'Particle_Type': particle_type,\n",
    "        'Cycles': cycles,\n",
    "        'Replicate': replicate\n",
    "    }\n",
    "\n",
    "def abbreviate_particle_type(particle_type):\n",
    "    \"\"\"Create abbreviation for particle type\"\"\"\n",
    "    if not particle_type:\n",
    "        return \"UNK\"\n",
    "    \n",
    "    # Common abbreviations\n",
    "    abbreviations = {\n",
    "        \"DBPC HMSN\": \"D\",\n",
    "        \"Control\": \"C\",\n",
    "        \"Blank\": \"B\",\n",
    "        # Add more abbreviations as needed\n",
    "    }\n",
    "    \n",
    "    if particle_type in abbreviations:\n",
    "        return abbreviations[particle_type]\n",
    "    \n",
    "    # If not in dictionary, use first letter of each word\n",
    "    words = particle_type.split()\n",
    "    if len(words) > 1:\n",
    "        return ''.join(word[0].upper() for word in words)\n",
    "    else:\n",
    "        return particle_type[:3].upper()\n",
    "\n",
    "def create_sheet_name(sample_info, sheet_type):\n",
    "    \"\"\"Create abbreviated sheet name within Excel's 31-character limit\"\"\"\n",
    "    # Abbreviate particle type\n",
    "    particle_abbrev = abbreviate_particle_type(sample_info['Particle_Type'])\n",
    "    \n",
    "    # Extract cycle number\n",
    "    cycles = sample_info['Cycles']\n",
    "    if cycles:\n",
    "        cycle_match = re.search(r'(\\d+)\\s*cycles?', cycles, re.IGNORECASE)\n",
    "        if cycle_match:\n",
    "            cycle_num = cycle_match.group(1)\n",
    "        else:\n",
    "            cycle_num = \"X\"\n",
    "    else:\n",
    "        cycle_num = \"X\"\n",
    "    \n",
    "    # Get replicate number\n",
    "    replicate = sample_info['Replicate'] or \"X\"\n",
    "    \n",
    "    # Sheet type abbreviations\n",
    "    sheet_abbrev = {\n",
    "        'Summary': 'S',\n",
    "        'Pore Data': 'P',\n",
    "        'Distribution Data': 'D',\n",
    "        'Cumulative Data': 'C'\n",
    "    }\n",
    "    \n",
    "    # Create sheet name\n",
    "    sheet_name = f\"{particle_abbrev}-{cycle_num}C-R{replicate}-{sheet_abbrev.get(sheet_type, 'X')}\"\n",
    "    \n",
    "    # Ensure it's within 31 characters (should be fine with this format)\n",
    "    return sheet_name[:31]\n",
    "\n",
    "def check_excel_structure(excel_file):\n",
    "    \"\"\"Check what sheets are available in the Excel file\"\"\"\n",
    "    try:\n",
    "        xl_file = pd.ExcelFile(excel_file)\n",
    "        return xl_file.sheet_names\n",
    "    except Exception as e:\n",
    "        print(f\"  Error reading {os.path.basename(excel_file)}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def find_excel_files(base_dir, pattern=\"*_pore_analysis_*.xlsx\"):\n",
    "    \"\"\"Recursively find all Excel files matching the pattern\"\"\"\n",
    "    excel_files = list(Path(base_dir).glob(f\"**/{pattern}\"))\n",
    "    \n",
    "    # If no files found with the default pattern, try a more general pattern\n",
    "    if not excel_files:\n",
    "        print(f\"No files found with pattern '{pattern}', trying more general pattern...\")\n",
    "        excel_files = list(Path(base_dir).glob(\"**/*pore*.xlsx\"))\n",
    "    \n",
    "    return [str(f) for f in excel_files]\n",
    "\n",
    "def copy_sheets_to_merged_file(excel_files, output_file):\n",
    "    \"\"\"Copy sheets from multiple Excel files to a single merged file\"\"\"\n",
    "    \n",
    "    # Track what sheets we've created and any naming conflicts\n",
    "    sheet_names_used = {}\n",
    "    sheets_copied = 0\n",
    "    \n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        for file_idx, excel_file in enumerate(excel_files):\n",
    "            print(f\"\\n  Processing file {file_idx + 1}/{len(excel_files)}: {os.path.basename(excel_file)}\")\n",
    "            \n",
    "            # Extract sample info\n",
    "            sample_info = extract_sample_info(excel_file)\n",
    "            \n",
    "            # Get available sheets\n",
    "            sheets = check_excel_structure(excel_file)\n",
    "            if not sheets:\n",
    "                print(f\"    No sheets found, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Process each sheet type\n",
    "            for sheet_type in ['Summary', 'Pore Data', 'Distribution Data', 'Cumulative Data']:\n",
    "                if sheet_type in sheets:\n",
    "                    try:\n",
    "                        # Read the sheet\n",
    "                        df = pd.read_excel(excel_file, sheet_name=sheet_type)\n",
    "                        \n",
    "                        # Create abbreviated sheet name\n",
    "                        sheet_name = create_sheet_name(sample_info, sheet_type)\n",
    "                        \n",
    "                        # Handle duplicates by adding a suffix\n",
    "                        original_sheet_name = sheet_name\n",
    "                        counter = 1\n",
    "                        while sheet_name in sheet_names_used:\n",
    "                            sheet_name = f\"{original_sheet_name}_{counter}\"\n",
    "                            counter += 1\n",
    "                            if len(sheet_name) > 31:  # Excel limit\n",
    "                                sheet_name = f\"{original_sheet_name[:28]}_{counter}\"\n",
    "                        \n",
    "                        # Write to the merged file\n",
    "                        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "                        sheet_names_used[sheet_name] = {\n",
    "                            'file': excel_file,\n",
    "                            'original_sheet': sheet_type,\n",
    "                            'sample_info': sample_info\n",
    "                        }\n",
    "                        sheets_copied += 1\n",
    "                        print(f\"    ✓ Copied '{sheet_type}' → '{sheet_name}'\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"    ✗ Error copying '{sheet_type}': {str(e)}\")\n",
    "                else:\n",
    "                    print(f\"    - '{sheet_type}' not found\")\n",
    "        \n",
    "        # Create a summary sheet with mapping information\n",
    "        summary_data = []\n",
    "        for sheet_name, info in sheet_names_used.items():\n",
    "            summary_data.append({\n",
    "                'Sheet_Name': sheet_name,\n",
    "                'Original_Sheet_Type': info['original_sheet'],\n",
    "                'Particle_Type': info['sample_info']['Particle_Type'],\n",
    "                'Cycles': info['sample_info']['Cycles'],\n",
    "                'Replicate': info['sample_info']['Replicate'],\n",
    "                'Source_File': os.path.basename(info['file'])\n",
    "            })\n",
    "        \n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_df = summary_df.sort_values(['Particle_Type', 'Cycles', 'Replicate', 'Original_Sheet_Type'])\n",
    "            summary_df.to_excel(writer, sheet_name='INDEX', index=False)\n",
    "            print(f\"\\n  ✓ Created INDEX sheet with mapping information\")\n",
    "        \n",
    "        # Auto-adjust column widths for ALL sheets\n",
    "        print(\"\\n  Adjusting column widths...\")\n",
    "        for sheet_name in writer.sheets:\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "            for column in worksheet.columns:\n",
    "                max_length = 0\n",
    "                column_letter = column[0].column_letter\n",
    "                \n",
    "                # Check header length\n",
    "                if column[0].value:\n",
    "                    max_length = len(str(column[0].value))\n",
    "                \n",
    "                # Check all cells in the column\n",
    "                for cell in column:\n",
    "                    try:\n",
    "                        if cell.value:\n",
    "                            cell_length = len(str(cell.value))\n",
    "                            if cell_length > max_length:\n",
    "                                max_length = cell_length\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                # Set width with a reasonable min/max\n",
    "                adjusted_width = max(8, min(max_length + 2, 50))\n",
    "                worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "    \n",
    "    return sheets_copied, sheet_names_used\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Use tkinter to select folder\n",
    "        import tkinter as tk\n",
    "        from tkinter import filedialog\n",
    "        \n",
    "        # Create root window and hide it\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        \n",
    "        # Make the dialog appear on top\n",
    "        root.lift()\n",
    "        root.attributes('-topmost', True)\n",
    "        \n",
    "        # Platform-specific methods to ensure window is on top\n",
    "        if platform.system() == 'Windows':\n",
    "            root.wm_attributes('-topmost', True)\n",
    "        elif platform.system() == 'Darwin':  # macOS\n",
    "            root.call('wm', 'attributes', '.', '-topmost', True)\n",
    "        \n",
    "        # Force focus\n",
    "        root.focus_force()\n",
    "        \n",
    "        # Small delay to ensure window comes to front\n",
    "        root.update()\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        # Ask user to select the base directory\n",
    "        print(\"Please select the folder containing your pore analysis Excel files...\")\n",
    "        print(\"(The file dialog should appear on top of other windows)\")\n",
    "        \n",
    "        base_dir = filedialog.askdirectory(\n",
    "            title=\"Select folder containing pore analysis Excel files\",\n",
    "            initialdir=os.path.expanduser(\"~\"),\n",
    "            parent=root\n",
    "        )\n",
    "        \n",
    "        # Destroy the root window after selection\n",
    "        root.destroy()\n",
    "        \n",
    "        if not base_dir:\n",
    "            print(\"No folder selected. Exiting...\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening folder dialog: {e}\")\n",
    "        print(\"\\nPlease enter the folder path manually:\")\n",
    "        base_dir = input(\"Folder path: \").strip()\n",
    "        if not os.path.exists(base_dir):\n",
    "            print(f\"Folder not found: {base_dir}\")\n",
    "            return\n",
    "    \n",
    "    print(f\"\\nSearching for Excel files in: {base_dir}\")\n",
    "    \n",
    "    # Find all Excel files matching the pattern\n",
    "    excel_files = find_excel_files(base_dir)\n",
    "    \n",
    "    if not excel_files:\n",
    "        print(\"No Excel files found matching pattern '*_pore_analysis_*.xlsx'\")\n",
    "        print(\"Make sure your files follow the naming convention: [name]_pore_analysis_[method].xlsx\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nFound {len(excel_files)} Excel files:\")\n",
    "    \n",
    "    # Show all files with sample info\n",
    "    for i, file in enumerate(excel_files, 1):\n",
    "        rel_path = os.path.relpath(file, base_dir)\n",
    "        sample_info = extract_sample_info(file)\n",
    "        print(f\"{i:3d}. {rel_path}\")\n",
    "        print(f\"      → {sample_info['Particle_Type']} | {sample_info['Cycles']} | Replicate {sample_info['Replicate']}\")\n",
    "    \n",
    "    # Ask user to confirm or filter\n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"  1. Merge all files\")\n",
    "    print(\"  2. Select specific files to merge\")\n",
    "    print(\"  3. Cancel\")\n",
    "    \n",
    "    choice = input(\"\\nEnter your choice (1-3): \")\n",
    "    \n",
    "    if choice == '3':\n",
    "        print(\"Merge cancelled.\")\n",
    "        return\n",
    "    elif choice == '2':\n",
    "        print(\"\\nEnter the numbers of files to merge (comma-separated, e.g., 1,3,5-8):\")\n",
    "        selection = input(\"File numbers: \")\n",
    "        \n",
    "        # Parse the selection\n",
    "        selected_indices = []\n",
    "        for part in selection.split(','):\n",
    "            part = part.strip()\n",
    "            if '-' in part:\n",
    "                start, end = map(int, part.split('-'))\n",
    "                selected_indices.extend(range(start-1, end))\n",
    "            else:\n",
    "                selected_indices.append(int(part)-1)\n",
    "        \n",
    "        # Filter files\n",
    "        excel_files = [excel_files[i] for i in selected_indices if 0 <= i < len(excel_files)]\n",
    "        print(f\"\\nSelected {len(excel_files)} files for merging.\")\n",
    "    \n",
    "    if not excel_files:\n",
    "        print(\"No files selected. Exiting...\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nProcessing {len(excel_files)} Excel files...\")\n",
    "    \n",
    "    # Create output filename in the same directory\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = os.path.join(base_dir, f\"MERGED_pore_analysis_{timestamp}.xlsx\")\n",
    "    \n",
    "    print(f\"\\nMerging sheets to: {output_file}\")\n",
    "    \n",
    "    # Copy all sheets with abbreviated names\n",
    "    sheets_copied, sheet_names_used = copy_sheets_to_merged_file(excel_files, output_file)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MERGE COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Output file: {os.path.basename(output_file)}\")\n",
    "    print(f\"Location: {os.path.dirname(output_file)}\")\n",
    "    print(f\"\\nTotal sheets copied: {sheets_copied}\")\n",
    "    print(\"\\nSheet naming convention:\")\n",
    "    print(\"  - Particle Type: First letter(s) (e.g., 'D' for DBPC HMSN)\")\n",
    "    print(\"  - Cycles: Number + 'C' (e.g., '0C' for 0 cycles)\")\n",
    "    print(\"  - Replicate: 'R' + number (e.g., 'R1' for replicate 1)\")\n",
    "    print(\"  - Sheet Type: S=Summary, P=Pore Data, D=Distribution, C=Cumulative\")\n",
    "    print(\"\\nExample: 'D-0C-R1-S' = DBPC HMSN, 0 cycles, Replicate 1, Summary sheet\")\n",
    "    print(\"\\nThe INDEX sheet contains the full mapping of abbreviated names to samples.\")\n",
    "    print(\"\\nDone! You can open the merged Excel file to view all results.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71898b33-659f-45c1-be5c-a47999a00df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (particle_tracker_real)",
   "language": "python",
   "name": "particle_tracker_real"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
